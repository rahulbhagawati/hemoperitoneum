{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b67cef77-71e9-425e-9e00-b80799e19263",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pydicom as py\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import skimage as sk\n",
    "import sys\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "from sklearn.feature_selection import RFECV\n",
    "\n",
    "\n",
    "#from sklearn import metrics\n",
    "from sklearn.metrics import make_scorer, confusion_matrix, precision_score, recall_score, accuracy_score, f1_score, roc_auc_score, balanced_accuracy_score, matthews_corrcoef\n",
    "\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "\n",
    "import shap\n",
    "from sklearn.inspection import permutation_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7adb601-9580-4190-aabb-f69ae1bdb73d",
   "metadata": {},
   "outputs": [],
   "source": [
    "root= \"the root/path of the folders\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "059f2364-a83d-4b82-a9d9-6b5319028a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load training, validation and testing data\n",
    "\n",
    "xtrain_df= pd.read_csv(root+ \"classification/\"+ \"xtrain_df.csv\")\n",
    "ytrain= np.load(root+ \"classification/\"+ \"ytrain.npy\",)\n",
    "print(\"Done\")\n",
    "\n",
    "\n",
    "xval_df= pd.read_csv(root+ \"classification/\"+ \"xval_df.csv\")\n",
    "yval= np.load(root+ \"classification/\"+ \"yval.npy\")\n",
    "print(\"Done\")\n",
    "\n",
    "\n",
    "xtest_df= pd.read_csv(root+ \"classification/\"+ \"xtest_df.csv\")\n",
    "ytest= np.load(root+ \"classification/\"+ \"ytest.npy\")\n",
    "print(\"Done\")\n",
    "\n",
    "print(f\"\\nTraining size= {xtrain_df.shape}\")\n",
    "print(f\"Validation size= {xval_df.shape}\")\n",
    "print(f\"Testing size= {xtest_df.shape}\")\n",
    "\n",
    "print(f\"\\nytrain= {np.unique(ytrain, return_counts= True)}\")\n",
    "print(f\"yval= {np.unique(yval, return_counts= True)}\")\n",
    "print(f\"ytest= {np.unique(ytest, return_counts= True)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e4c77d9-6ff0-4261-b3a4-c6835bb45133",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the custom scorers\n",
    "\n",
    "# Custom scorer for True Negative Rate (TNR)\n",
    "def tnr(y_true, y_pred):\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    return tn / (tn + fp)\n",
    "\n",
    "\n",
    "\n",
    "mcc_scorer= make_scorer(matthews_corrcoef)\n",
    "balanced_accuracy_scorer= make_scorer(balanced_accuracy_score)\n",
    "precision_scorer = make_scorer(precision_score)\n",
    "recall_scorer = make_scorer(recall_score)\n",
    "f1_scorer= make_scorer(f1_score)\n",
    "roc_auc_scorer= make_scorer(roc_auc_score)\n",
    "tnr_scorer = make_scorer(tnr)\n",
    "\n",
    "\n",
    "# CCS function\n",
    "def compute_ccs(metrics_dict):\n",
    "    selected_metrics = [\n",
    "        metrics_dict[\"Balanced Accuracy\"],\n",
    "        metrics_dict[\"F1 Score\"],\n",
    "        metrics_dict[\"ROC_AUC\"],\n",
    "        metrics_dict[\"MCC\"]\n",
    "    ]\n",
    "    return gmean([max(0, metric) for metric in selected_metrics])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d09aaa-b6b5-4170-bcdd-dd9be1208c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random Forest Classifier for training on the training data and then evaluate on the validation data\n",
    "\n",
    "def train_and_evaluate(train_x, train_y, val_x, val_y, test_x, test_y):\n",
    "    \n",
    "    # Store CCS scores across multiple random runs\n",
    "    val_ccs_scores = []\n",
    "    test_ccs_scores= []\n",
    "\n",
    "    \n",
    "    for seed in range(20):  # Loop over 20 different random states\n",
    "        model = RandomForestClassifier(250, random_state= seed, n_jobs= -1, class_weight= \"balanced\")\n",
    "        model.fit(train_x, train_y)\n",
    "\n",
    "        # Validate\n",
    "        val_predictions = model.predict(val_x)\n",
    "        val_probabilities = model.predict_proba(val_x)[:, 1]  # For ROC AUC\n",
    "\n",
    "        val_metrics = {\n",
    "            \"Balanced Accuracy\": balanced_accuracy_score(val_y, val_predictions),\n",
    "            \"F1 Score\": f1_score(val_y, val_predictions),\n",
    "            \"ROC_AUC\": roc_auc_score(val_y, val_probabilities),\n",
    "            \"MCC\": matthews_corrcoef(val_y, val_predictions)\n",
    "        }\n",
    "\n",
    "        val_ccs = (compute_ccs(val_metrics)*100)\n",
    "        val_ccs_scores.append(val_ccs)\n",
    "\n",
    "\n",
    "        # Testing\n",
    "        test_predictions = model.predict(test_x)\n",
    "        test_probabilities = model.predict_proba(test_x)[:, 1]  # For ROC AUC\n",
    "\n",
    "        test_metrics = {\n",
    "            \"Balanced Accuracy\": balanced_accuracy_score(test_y, test_predictions),\n",
    "            \"F1 Score\": f1_score(test_y, test_predictions),\n",
    "            \"ROC_AUC\": roc_auc_score(test_y, test_probabilities),\n",
    "            \"MCC\": matthews_corrcoef(test_y, test_predictions)\n",
    "        }\n",
    "\n",
    "        test_ccs = (compute_ccs(test_metrics)*100)\n",
    "        test_ccs_scores.append(test_ccs)\n",
    "\n",
    "\n",
    "    # Print final CCS\n",
    "    print(\"\\n\")\n",
    "    print(f\"Validation CCS = {val_ccs_scores}\")\n",
    "    print(f\"Mean validation CCS = {round(np.mean(val_ccs_scores), 3)}\")\n",
    "\n",
    "    print(f\"\\nTesting CCS = {test_ccs_scores}\")\n",
    "    print(f\"Mean testing CCS = {round(np.mean(test_ccs_scores), 3)}\\n\")\n",
    "\n",
    "    return np.array(val_ccs_scores), np.array(test_ccs_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f697d0-76ec-49cb-9ad4-74d3da70a1a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#RFC feature importance (FI)\n",
    "\n",
    "feature_importances= 0\n",
    "fi_scores= []  # Store all runs\n",
    "\n",
    "\n",
    "k= 100\n",
    "for i in range(k):\n",
    "    rfc = RandomForestClassifier(250, random_state=i, n_jobs=-1, class_weight=\"balanced\")\n",
    "    history = rfc.fit(xtrain_df, ytrain)\n",
    "    \n",
    "    # Store each run's importance scores\n",
    "    fi_scores.append(rfc.feature_importances_)\n",
    "    feature_importances += rfc.feature_importances_\n",
    "    \n",
    "    print(f\"{i+1}) Done.\")\n",
    "\n",
    "\n",
    "\n",
    "# Calculate mean RF_FI\n",
    "fi = feature_importances/k\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#MinMax scaling is used for normalizing the scores to bring them to a same range for comparison.\n",
    "rfc_fi= pd.DataFrame({\"feature\": xtrain_df.columns, \"mean_fi\": fi})\n",
    "\n",
    "\n",
    "# Normalize FI\n",
    "rfc_fi['fi_normalized'] = MinMaxScaler(feature_range=(0, 1)).fit_transform(rfc_fi[['mean_fi']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb0c9329-6176-40cb-bdaa-b3da478628bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"SHAP Averaging\" or \"Ensemble SHAP\"\n",
    "\n",
    "# Initialize variables\n",
    "shap_score = None  # Start with None since we don't know the shape yet\n",
    "shap_scores = []   # Store SHAP values for all runs\n",
    "\n",
    "\n",
    "k = 100  # Number of runs\n",
    "\n",
    "for i in range(k):\n",
    "    # Train the Random Forest model\n",
    "    rfc = RandomForestClassifier(250, random_state=i, n_jobs=-1, class_weight=\"balanced\")\n",
    "    history = rfc.fit(xtrain_df, ytrain)\n",
    "    \n",
    "    # Compute SHAP values\n",
    "    explainer = shap.TreeExplainer(rfc)\n",
    "    shap_value = explainer.shap_values(np.array(xtrain_df), check_additivity=False)  # Returns a list for classification\n",
    "    \n",
    "\n",
    "    \n",
    "    shap_scores.append(shap_value[1])  # Append the current run's SHAP values\n",
    "\n",
    "    \n",
    "    # Accumulate SHAP values (initialize shap_score as an array on the first iteration)\n",
    "    if shap_score is None:\n",
    "        shap_score = np.array(shap_value[1])  # Initialize as a NumPy array\n",
    "    else:\n",
    "        shap_score += np.array(shap_value[1])  # Add to the accumulated SHAP values\n",
    "    \n",
    "    print(f\"{i+1}) SHAP calculation done.\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Absolute average SHAP values across all runs\n",
    "sh = np.mean(np.abs(shap_score), axis=0) / k\n",
    "\n",
    "\n",
    "#MinMax scaling is used for normalizing the scores to bring them to a same range for comparison.\n",
    "rfc_shap= pd.DataFrame({\"feature\": xtrain_df.columns, \"si\": sh})\n",
    "\n",
    "\n",
    "# Normalize SHAP\n",
    "rfc_shap['si_normalized'] = MinMaxScaler(feature_range=(0, 1)).fit_transform(rfc_shap[['si']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb906701-f867-4be7-9eef-ec1e1763e73e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Permutation importance (PI)\n",
    "\n",
    "rfc = RandomForestClassifier(250, random_state= 61, n_jobs= -1, class_weight= \"balanced\")\n",
    "\n",
    "perm_importance= permutation_importance(rfc, xtrain_df, ytrain, scoring= make_scorer(f1_score, average= \"binary\"),\n",
    "                                        n_repeats= 100, random_state= 51, n_jobs= -1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#MinMax scaling is used for normalizing the scores to bring them to a same range for comparison.\n",
    "rfc_pi= pd.DataFrame({\"feature\": xtrain_df.columns, \"pi\": perm_importance.importances_mean})\n",
    "\n",
    "# Normalize PI\n",
    "rfc_pi['pi_normalized'] = MinMaxScaler(feature_range=(0, 1)).fit_transform(rfc_pi[['pi']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92af3484-57f3-421c-b41d-94f306e2a4d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Concatenate all importance scores\n",
    "\n",
    "rfc_fs= pd.DataFrame({\"feature\": xtrain_df.columns, \"fi_normalized\": rfc_fi['fi_normalized'], \n",
    "                          \"si_normalized\": rfc_shap['si_normalized'], \"pi_normalized\": rfc_pi[\"pi_normalized\"]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d5842f-1e18-4fb1-8c51-47eb4c9bead3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c06515-bf7e-4145-923d-dcd280492495",
   "metadata": {},
   "outputs": [],
   "source": [
    "                                                        #Feature Selection Strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d669e1a2-d71e-47e2-ae72-598bb4a80b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#RF Feature Importance\n",
    "\n",
    "fi_mean= round(np.mean(rfc_fs[\"fi_normalized\"]), 5)\n",
    "fi_std= round(np.std(rfc_fs[\"fi_normalized\"]), 5)\n",
    "fi_ci_lower= round(np.percentile(rfc_fs[\"fi_normalized\"], 2.5), 5)\n",
    "fi_ci_upper= round(np.percentile(rfc_fs[\"fi_normalized\"], 97.5), 5)\n",
    "\n",
    "print(f\"RF Feature Importance\\nMean= {fi_mean}\\nStdev= {fi_std}\\n95_CI_lower= {fi_ci_lower}\\n95_CI_upper= {fi_ci_upper}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b5e691a-d7c9-4702-b1f1-43e162522aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SHAP values\n",
    "\n",
    "si_mean= round(np.mean(rfc_fs[\"si_normalized\"]), 5)\n",
    "si_std= round(np.std(rfc_fs[\"si_normalized\"]), 5)\n",
    "si_ci_lower= round(np.percentile(rfc_fs[\"si_normalized\"], 2.5), 5)\n",
    "si_ci_upper= round(np.percentile(rfc_fs[\"si_normalized\"], 97.5), 5)\n",
    "\n",
    "print(f\"SHAP values\\nMean= {si_mean}\\nStdev= {si_std}\\n95_CI_lower= {si_ci_lower}\\n95_CI_upper= {si_ci_upper}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac47ecea-9828-4abe-a5ac-021e0fecdf1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Permutation Importance\n",
    "\n",
    "pi_mean= round(np.mean(rfc_fs[\"pi_normalized\"]), 5)\n",
    "pi_std= round(np.std(rfc_fs[\"pi_normalized\"]), 5)\n",
    "pi_ci_lower= round(np.percentile(rfc_fs[\"pi_normalized\"], 2.5), 5)\n",
    "pi_ci_upper= round(np.percentile(rfc_fs[\"pi_normalized\"], 97.5), 5)\n",
    "\n",
    "print(f\"Permutation Importance\\nMean= {pi_mean}\\nStdev= {pi_std}\\n95_CI_lower= {pi_ci_lower}\\n95_CI_upper= {pi_ci_upper}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "721ca4e5-6d6f-4ebd-b762-8c1668e2c460",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f475677f-ae9b-4055-be89-9856d1364458",
   "metadata": {},
   "outputs": [],
   "source": [
    "                    # Feature selection based on Means as thresholds (Best results was achieved using Mean as thresholds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d0d7e9-8762-4108-8a52-f3213f01fd35",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_rfc_fi= rfc_fs_val.loc[rfc_fs_val[\"fi_normalized\"] >= fi_mean, \"feature\"].tolist()\n",
    "print(\"Total=\", np.shape(rfc_fs_val)[0])\n",
    "print(\"Retained=\", len(cols_rfc_fi))\n",
    "print(\"Rejected=\", np.shape(rfc_fs_val)[0] - len(cols_rfc_fi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e5a3c48-514d-42ec-a5ab-66541eeaf708",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_rfc_si= rfc_fs_val.loc[rfc_fs_val[\"si_normalized\"] >= si_mean, \"feature\"].tolist()\n",
    "print(\"Total=\", np.shape(rfc_fs_val)[0])\n",
    "print(\"Retained=\", len(cols_rfc_si))\n",
    "print(\"Rejected=\", np.shape(rfc_fs_val)[0] - len(cols_rfc_si))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac377311-c23b-4a7d-88e3-456d89f1eb93",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_rfc_pi= rfc_fs_val.loc[rfc_fs_val[\"pi_normalized\"] >= pi_mean, \"feature\"].tolist()\n",
    "print(\"Total=\", np.shape(rfc_fs_val)[0])\n",
    "print(\"Retained=\", len(cols_rfc_pi))\n",
    "print(\"Rejected=\", np.shape(rfc_fs_val)[0] - len(cols_rfc_pi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6962453-f114-4b4f-a42e-6a0624c4d6f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c8d699-467a-46f8-8e42-549831db0e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best result was achieved at AND operation\n",
    "# Features selected from all methods combined, where threshold is crossed in all 3 methods: AND.\n",
    "\n",
    "cols_selected= list((set(cols_rfc_fi) & set(cols_rfc_si) & set(cols_rfc_pi)))\n",
    "\n",
    "print(\"Total=\", np.shape(rfc_fs_val)[0])\n",
    "print(\"If combined, features retained=\", len(cols_selected))\n",
    "print(\"If combined, features rejected=\", np.shape(rfc_fs_val)[0] - len(cols_selected))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44fb03ee-8629-4b4a-a7a2-531024b29584",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0128518-8b78-4267-ae5f-39f660c0dcd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "                                  #RFECV on the data: from feature selection based on Means as thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb86bbc-0ee7-4288-9d75-4c29951e3ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_red= xtrain_df[cols_selected]\n",
    "x_val_red= xval_df[cols_selected]\n",
    "\n",
    "print(x_train_red.shape)\n",
    "print(x_val_red.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db5d3503-fc76-47c1-9c45-378972e50b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "#RFECV for s-kfold= 20 for different step-sizes\n",
    "\n",
    "for i in range(100, 4, -5):\n",
    "    print(\"\\n*************************************************\\nStep-size=\", i)\n",
    "    \n",
    "    rfc= RandomForestClassifier(n_estimators= 250, random_state= 46, n_jobs= -1, class_weight= \"balanced\")\n",
    "    skf= StratifiedKFold(20, shuffle= True, random_state= 11)\n",
    "    \n",
    "    rfecv = RFECV(estimator= rfc, step= i, cv= skf, scoring= mcc_scorer, n_jobs= -1)\n",
    "    \n",
    "    rfecv.fit(x_train_red, ytrain)\n",
    "    selected_features = x_train_red.columns[rfecv.support_]\n",
    "    print(f\"Optimal number of features: {rfecv.n_features_}\")\n",
    "    \n",
    "    train_and_evaluate(x_train_red[selected_features], ytrain, x_val_red[selected_features], yval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31640c2b-4c39-41b2-8d97-a30133c5bb0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Best result was achieved at step-size= 30\n",
    "\n",
    "rfc= RandomForestClassifier(n_estimators= 250, random_state= 46, n_jobs= -1, class_weight= \"balanced\")\n",
    "skf= StratifiedKFold(20, shuffle= True, random_state= 11)\n",
    "\n",
    "rfecv = RFECV(estimator= rfc, step= 30, cv= skf, scoring= mcc_scorer, n_jobs= -1)\n",
    "\n",
    "rfecv.fit(x_train_red, ytrain)\n",
    "selected_features = x_train_red.columns[rfecv.support_]\n",
    "print(f\"Optimal number of features: {rfecv.n_features_}\")\n",
    "\n",
    "train_and_evaluate(x_train_red[selected_features], ytrain, x_val_red[selected_features], yval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5994bfa5-ce8a-4b37-bd76-745f1cd29d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'selected_features' is an Index object\n",
    "selected_features_df = pd.DataFrame(selected_features, columns=['Feature'])\n",
    "\n",
    "# Save it as a CSV file\n",
    "selected_features_df.to_csv(root+ \"classification/rfecv_cols_df.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c49fff28-6711-4110-b824-4dc39b712e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "                    #Save xtrain, xval and xtest datasets using the selected_features as columns only for subsequesnt analyses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c48cc2-33b5-404c-822e-bf805dd78741",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
