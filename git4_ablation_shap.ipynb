{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "971ff253-8425-44f7-bece-d09ba0845deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pydicom as py\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import skimage as sk\n",
    "import sys\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "\n",
    "#from sklearn.feature_selection import RFECV\n",
    "from scipy.stats import gmean\n",
    "\n",
    "#from sklearn import metrics\n",
    "from sklearn.metrics import make_scorer, confusion_matrix, precision_score, recall_score, accuracy_score, f1_score, roc_auc_score, balanced_accuracy_score, matthews_corrcoef\n",
    "\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from scipy.stats import wilcoxon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "191758ff-88ae-49ca-b97f-c427f08dba77",
   "metadata": {},
   "outputs": [],
   "source": [
    "root= \"the root/path of the folders\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a00c205-3a58-40aa-a9a2-b6f319ff8d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load training, validation and testing data\n",
    "\n",
    "xtrain_df= pd.read_csv(root+ \"classification/\"+ \"xtrain_df.csv\")\n",
    "ytrain= np.load(root+ \"classification/\"+ \"ytrain.npy\",)\n",
    "print(\"Done\")\n",
    "\n",
    "\n",
    "xval_df= pd.read_csv(root+ \"classification/\"+ \"xval_df.csv\")\n",
    "yval= np.load(root+ \"classification/\"+ \"yval.npy\")\n",
    "print(\"Done\")\n",
    "\n",
    "\n",
    "xtest_df= pd.read_csv(root+ \"classification/\"+ \"xtest_df.csv\")\n",
    "ytest= np.load(root+ \"classification/\"+ \"ytest.npy\")\n",
    "print(\"Done\")\n",
    "\n",
    "print(f\"\\nTraining size= {xtrain_df.shape}\")\n",
    "print(f\"Validation size= {xval_df.shape}\")\n",
    "print(f\"Testing size= {xtest_df.shape}\")\n",
    "\n",
    "print(f\"\\nytrain= {np.unique(ytrain, return_counts= True)}\")\n",
    "print(f\"yval= {np.unique(yval, return_counts= True)}\")\n",
    "print(f\"ytest= {np.unique(ytest, return_counts= True)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ec7ba3-0402-445f-924a-3d639fd01390",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the feature-reduced RFECV dataset\n",
    "\n",
    "xtrain_rfecv= pd.read_csv(root+ \"classification/xtrain_rfecv.csv\")\n",
    "xval_rfecv= pd.read_csv(root+ \"classification/xval_rfecv.csv\")\n",
    "xtest_rfecv= pd.read_csv(root+ \"classification/xtest_rfecv.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27424515-5e63-4548-a68c-6222af6c9097",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load each of the individual columns of each feature groups from the feature-reduced RFECV dataset\n",
    "\n",
    "pca_fc= (pd.read_csv(root+ \"classification/PCA rfecv.csv\").Feature).astype(str)\n",
    "fo_fc= (pd.read_csv(root+ \"classification/FO rfecv.csv\").Feature).astype(str)\n",
    "glcm_fc= (pd.read_csv(root+ \"classification/GLCM rfecv.csv\").Feature).astype(str)\n",
    "glrlm_fc= (pd.read_csv(root+ \"classification/GLRLM rfecv.csv\").Feature).astype(str)\n",
    "glszm_fc= (pd.read_csv(root+ \"classification/GLSZM rfecv.csv\").Feature).astype(str)\n",
    "gldm_fc= (pd.read_csv(root+ \"classification/GLDM rfecv.csv\").Feature).astype(str)\n",
    "ngtdm_fc= (pd.read_csv(root+ \"classification/NGTDM rfecv.csv\").Feature).astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "177c6858-75ab-42df-9457-dc514f8eb2fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c0dd693-8424-436c-a07d-25dc76920076",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the custom scorers\n",
    "\n",
    "# Custom scorer for True Negative Rate (TNR)\n",
    "def tnr(y_true, y_pred):\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    return tn / (tn + fp)\n",
    "\n",
    "\n",
    "\n",
    "mcc_scorer= make_scorer(matthews_corrcoef)\n",
    "balanced_accuracy_scorer= make_scorer(balanced_accuracy_score)\n",
    "precision_scorer = make_scorer(precision_score)\n",
    "recall_scorer = make_scorer(recall_score)\n",
    "f1_scorer= make_scorer(f1_score)\n",
    "roc_auc_scorer= make_scorer(roc_auc_score)\n",
    "tnr_scorer = make_scorer(tnr)\n",
    "\n",
    "\n",
    "# CCS function\n",
    "def compute_ccs(metrics_dict):\n",
    "    selected_metrics = [\n",
    "        metrics_dict[\"Balanced Accuracy\"],\n",
    "        metrics_dict[\"F1 Score\"],\n",
    "        metrics_dict[\"ROC_AUC\"],\n",
    "        metrics_dict[\"MCC\"]\n",
    "    ]\n",
    "    return gmean([max(0, metric) for metric in selected_metrics])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d706f6-3c0f-4d83-90e7-b4b0e0291647",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(train_x, train_y, val_x, val_y):\n",
    "    # Store CCS scores across multiple random runs\n",
    "    val_ccs_scores = []\n",
    "\n",
    "    #print(\"\\n***********************************************\")\n",
    "    for seed in range(20):  # Loop over 20 different random states\n",
    "        rfc = RandomForestClassifier(250, random_state=seed, n_jobs=-1, class_weight=\"balanced\")\n",
    "        rfc.fit(train_x, train_y)\n",
    "\n",
    "        # Validate\n",
    "        val_predictions = rfc.predict(val_x)\n",
    "        val_probabilities = rfc.predict_proba(val_x)[:, 1]  # For ROC AUC\n",
    "\n",
    "        val_metrics = {\n",
    "            \"Balanced Accuracy\": balanced_accuracy_score(val_y, val_predictions),\n",
    "            \"F1 Score\": f1_score(val_y, val_predictions),\n",
    "            \"ROC_AUC\": roc_auc_score(val_y, val_probabilities),\n",
    "            \"MCC\": matthews_corrcoef(val_y, val_predictions)\n",
    "        }\n",
    "\n",
    "        val_ccs = (compute_ccs(val_metrics)*100)\n",
    "        val_ccs_scores.append(val_ccs)\n",
    "\n",
    "\n",
    "    # Compute final CCS\n",
    "    #print(\"***********************************************\")\n",
    "    print(f\"Validation CCS = {val_ccs_scores}\")\n",
    "    print(f\"Mean validation CCS = {round(np.mean(val_ccs_scores), 3)}\")\n",
    "    return np.array(val_ccs_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d832343-6d5e-4012-90ca-cff2e05e5370",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_rfecv= train_and_evaluate(xtrain_rfecv, ytrain, xval_rfecv, yval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff953a18-9d60-484a-b9b4-42466757f41d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e65d48-2fe6-4e37-9190-6196e7363440",
   "metadata": {},
   "outputs": [],
   "source": [
    "                                                        #Ablation study, part-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b047a9eb-d0d8-4c30-837d-b386127d60fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "                                #Checking the performance by dropping individual feature sets from the RFECV data\n",
    "                                            #Do not use PCA as it is not a radiomics feature group.\n",
    "\n",
    "\n",
    "excluded_ccs= {}\n",
    "\n",
    "for name, cols in zip([\"PCA\", \"FO\", \"GLCM\", \"GLRLM\", \"GLSZM\", \"GLDM\", \"NGTDM\"], \n",
    "                      [pca_fc, fo_fc, glcm_fc, glrlm_fc, glszm_fc, gldm_fc, ngtdm_fc]):\n",
    "    \n",
    "    print(\"*****************************************\")\n",
    "    print(f\"Removed {name}= {len(cols)}\")\n",
    "    \n",
    "    xtrain_df2= xtrain_rfecv.drop(cols, axis=1)\n",
    "    xval_df2= xval_rfecv.drop(cols, axis=1)\n",
    "    xtest_df2= xtest_rfecv.drop(cols, axis=1)\n",
    "    print(\"Remaining columns=\", np.shape(xtrain_df2)[1])\n",
    "    \n",
    "    excluded_ccs[name]= train_and_evaluate(xtrain_df2, ytrain, xval_df2, yval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f73015-6c84-4960-98cf-4a4d13ca18fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "                    #Testing significance of differences of validation CCS between (RFECV) and individual (Leave-one-out) datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a54744cc-01ce-4fe7-bc8a-ab31e6a7c0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "for group, excluded_ccs in excluded_ccs.items():\n",
    "    stat, p_value = wilcoxon(val_rfecv, excluded_ccs)\n",
    "    print(f\"\\n\\nExcluding {group}:\")\n",
    "    print(f\"  Statistic = {stat:.2f}, p-value = {p_value:.4f}\")\n",
    "    if p_value < 0.05:\n",
    "        print(f\" Significant drop in CCS (p < 0.05) - {group} is important\")\n",
    "    else:\n",
    "        print(f\" No significant drop in CCS (p >= 0.05) - {group} may be less critical\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f7810e-be88-412d-8ea3-7958613f2284",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d108ed-0070-4ba4-9338-6b9cd60bb377",
   "metadata": {},
   "outputs": [],
   "source": [
    "                                                        #Ablation study, part-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c8deb82-0af0-41ce-86a8-07f1ce514ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "                #Checking the performance measures for individual groups addition to the PCA RFECV with statistical tests\n",
    "\n",
    "for name, cols in zip([\"GLSZM features\", \"GLDM features\", \"NGTDM features\", \"GLRLM features\", \"GLCM features\", \"FO features\"], \n",
    "                      [glszm_fc, gldm_fc, ngtdm_fc, glrlm_fc, glcm_fc, fo_fc]):\n",
    "\n",
    "    features= pca_fc\n",
    "    l1= len(features)\n",
    "    \n",
    "    features= pd.concat([features, cols], axis= 0)\n",
    "    print(\"*****************************************\")\n",
    "    print(f\"Length of the added {name}= {len(features)-l1}\")\n",
    "    \n",
    "    val_group= train_and_evaluate(xtrain_rfecv[features], ytrain, xval_rfecv[features], yval)\n",
    "\n",
    "    \n",
    "    \n",
    "    stat, p_value = wilcoxon(val_rfecv, val_group)\n",
    "    print(f\"\\nStatistic = {stat:.2f}, p-value = {p_value:.4f}\")\n",
    "    \n",
    "    print(\"Mean diff:\", np.mean(np.array(val_group) - np.array(val_rfecv)))\n",
    "    \n",
    "    if p_value < 0.05:\n",
    "        print(f\"Significant drop in CCS (p < 0.05) - {name} is important.\\n\")\n",
    "    else:\n",
    "        print(f\"No significant drop in CCS (p >= 0.05) - {name} may be less critical.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "948c1ec9-5f67-4461-8708-8b9a676576be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36651590-e658-496d-ad59-c919cd1a4e77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62fed4c9-990e-41ff-854f-e4fcc34106ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "        #Testing incremental addition of significant feature sets ranked as per their mean validation CCS in (PCA + groups)\n",
    "\n",
    "features= pca_fc\n",
    "f= []\n",
    "\n",
    "for name, cols in zip([\"GLRLM\", \"GLDM\", \"FO\"], [glrlm_fc, gldm_fc, fo_fc]):\n",
    "\n",
    "    f.append(name)\n",
    "    \n",
    "    #l1= len(features)\n",
    "    features= pd.concat([features, cols], axis= 0)\n",
    "    print(\"*****************************************\")\n",
    "    #print(f\"Length of the added {name}= {len(features)-l1}\")\n",
    "\n",
    "    print(f\"Added to PCA: {f}\")\n",
    "    \n",
    "    val_group= train_and_evaluate(xtrain_rfecv[features], ytrain, xval_rfecv[features], yval)\n",
    "\n",
    "    \n",
    "    stat, p_value = wilcoxon(val_rfecv, val_group)\n",
    "    print(f\"\\nStatistic = {stat:.2f}, p-value = {p_value:.4f}\")\n",
    "    print(\"Mean diff:\", np.mean(np.array(val_group) - np.array(val_rfecv)))\n",
    "    \n",
    "    if p_value < 0.05:\n",
    "        print(f\"Significant drop in CCS (p < 0.05) - {name} is important.\\n\")\n",
    "    else:\n",
    "        print(f\"No significant drop in CCS (p >= 0.05) - {name} may be less critical.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27bcdfb3-662d-4735-ba49-802212642f44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a356ed-2018-4c3c-b8ae-5d97aaf121e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finalize the RFECV dataset with the significant feature groups only: PCA + GLRLM + GLDM + FO\n",
    "\n",
    "features= pd.concat([pca_fc, glrlm_fc, gldm_fc, fo_fc], axis= 0)\n",
    "xtrain_reduced_rfecv= xtrain_rfecv[features]\n",
    "xval_reduced_rfecv= xval_rfecv[features]\n",
    "xtest_reduced_rfecv= xtest_rfecv[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a22051-0683-49e8-bd4e-578d85791a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain_reduced_rfecv.to_csv(root+ \"classification/xtrain_reduced_rfecv.csv\", index=False)\n",
    "xval_reduced_rfecv.to_csv(root+ \"classification/xval_reduced_rfecv.csv\", index=False)\n",
    "xtest_reduced_rfecv.to_csv(root+ \"classification/xtest_reduced_rfecv.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e474c8b6-2fa9-4153-9341-3bdedf613d5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "760d6710-ee6f-466f-94f0-1cf530ca9197",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b909418-585d-4472-ad4d-7161ee5e779b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f91d4bc-c3d5-42d8-9a51-56a1ff517223",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d6bf220-52d9-4d33-a92c-9c571c94c7db",
   "metadata": {},
   "outputs": [],
   "source": [
    "                        #SHAP for Feature Importance for statistically significant feature groups: PCA+ GLRLM + GLDM + FO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70609891-a36b-4aea-af91-542a68e699d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"SHAP Averaging\" or \"Ensemble SHAP\" on training data\n",
    "\n",
    "# Initialize variables\n",
    "shap_score = None  # Start with None since we don't know the shape yet\n",
    "shap_scores = []   # Store SHAP values for all runs\n",
    "\n",
    "\n",
    "k = 10  # Number of runs\n",
    "\n",
    "for i in range(k):\n",
    "    # Train the Random Forest model\n",
    "    rfc = RandomForestClassifier(250, random_state=i, n_jobs=-1, class_weight=\"balanced\")\n",
    "    history = rfc.fit(xtrain_reduced_rfecv, ytrain)\n",
    "    \n",
    "    # Compute SHAP values\n",
    "    explainer = shap.TreeExplainer(rfc)\n",
    "    shap_value = explainer.shap_values(np.array(xtrain_reduced_rfecv), check_additivity=False)  # Returns a list for classification\n",
    "    \n",
    "\n",
    "    \n",
    "    shap_scores.append(shap_value[1])  # Append the current run's SHAP values\n",
    "\n",
    "    \n",
    "    # Accumulate SHAP values (initialize shap_score as an array on the first iteration)\n",
    "    if shap_score is None:\n",
    "        shap_score = np.array(shap_value[1])  # Initialize as a NumPy array\n",
    "    else:\n",
    "        shap_score += np.array(shap_value[1])  # Add to the accumulated SHAP values\n",
    "    \n",
    "    print(f\"{i+1}) SHAP calculation done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c92ecf9-aac8-454e-9ec7-8b90138919cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Absolute average SHAP values across all runs\n",
    "shap_score= shap_score/k\n",
    "np.save(root+ \"classification/reduced_rfecv_shap_scores.npy\", shap_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc2bf33e-7da6-43d0-8531-7472ed270d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Absolute average SHAP values across all runs\n",
    "sh = np.mean(np.abs(shap_score), axis=0)  # NP.MEAN(axis=0) to average across all rows.\n",
    "\n",
    "# Display results\n",
    "print(\"Averaged SHAP values:\", sh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "652a7ea8-1ed3-4897-bde9-d896af169edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MinMax scaling is used for normalizing the importance scores to bring them to a same range for comparison.\n",
    "\n",
    "reduced_rfecv_shap= pd.DataFrame({\"feature\": xtrain_reduced_rfecv.columns, \"si\": sh})\n",
    "\n",
    "\n",
    "# Normalize RF importance\n",
    "reduced_rfecv_shap['si_normalized'] = MinMaxScaler(feature_range=(0, 1)).fit_transform(reduced_rfecv_shap[['si']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ba1431-63e0-4f0a-90ab-a81f4eb23fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map features to groups\n",
    "\n",
    "group_mapping = {}\n",
    "\n",
    "\n",
    "for feat in list(reduced_rfecv_shap['feature']):\n",
    "    if feat in pca_fc.values:\n",
    "        group_mapping[feat] = 'PCA'\n",
    "    elif feat in fo_fc.values:\n",
    "        group_mapping[feat] = 'FO'\n",
    "    elif feat in glrlm_fc.values:\n",
    "        group_mapping[feat] = 'GLRLM'\n",
    "    elif feat in gldm_fc.values:\n",
    "        group_mapping[feat] = 'GLDM'\n",
    "    else:\n",
    "        group_mapping[feat] = 'Unknown'  # Catch any unmapped features\n",
    "\n",
    "\n",
    "# Add group column to DataFrame\n",
    "reduced_rfecv_shap['group'] = reduced_rfecv_shap['feature'].map(group_mapping)\n",
    "\n",
    "\n",
    "# Aggregate SHAP values by group\n",
    "group_shap = reduced_rfecv_shap.groupby('group')['si'].sum().sort_values(ascending=False)\n",
    "\n",
    "\n",
    "# Calculate total SHAP for percentage contribution\n",
    "total_shap = group_shap.sum()\n",
    "group_shap_percent = (group_shap / total_shap * 100).round(2)\n",
    "\n",
    "\n",
    "# Display results\n",
    "print(\"\\nSHAP Importance by Feature Group:\")\n",
    "print(group_shap)\n",
    "print(\"\\nPercentage Contribution by Feature Group:\")\n",
    "print(group_shap_percent)\n",
    "\n",
    "\n",
    "# Optional: Check for unmapped features\n",
    "unmapped = reduced_rfecv_shap[reduced_rfecv_shap['group'] == 'Unknown']\n",
    "if not unmapped.empty:\n",
    "    print(f\"\\nWarning: {len(unmapped)} features not mapped to any group:\", unmapped['feature'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13996f0a-c479-418c-a9e4-e737b01b8e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the dataframe to a CSV file\n",
    "reduced_rfecv_shap.to_csv(root+ \"classification/reduced_rfecv_shap.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "677795df-79f6-41db-aa6a-866d14526463",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
